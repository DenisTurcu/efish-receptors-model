{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import mat73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_waveform(fname, fraction_of_max=2e-2):\n",
    "    data = sio.loadmat(fname)\n",
    "    k = list(data.keys())[-1]\n",
    "    data = data[k]\n",
    "\n",
    "    base_waveform = data[\"waveform\"][0][-1].flatten()\n",
    "    max_base_waveform = np.abs(base_waveform).max()\n",
    "    ids_good = np.where(np.abs(base_waveform) > fraction_of_max * max_base_waveform)[0]\n",
    "\n",
    "    waveforms = []\n",
    "    for i in range(len(data[\"waveform\"][0]) - 1):\n",
    "        waveform = data[\"waveform\"][0][i].flatten()\n",
    "        waveform = waveform[ids_good[0] : ids_good[-1]]\n",
    "        waveform = waveform / max_base_waveform\n",
    "        waveform = waveform - waveform[0]\n",
    "        waveforms.append(waveform)\n",
    "    base_waveform = base_waveform[ids_good[0] : ids_good[-1]] / max_base_waveform\n",
    "    base_waveform = base_waveform - base_waveform[0]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        dict(\n",
    "            stimulus_fname=[x[0] for x in data[\"fname\"][0]],\n",
    "            stimulus_marker=[x[0][0] for x in data[\"marker\"][0]],\n",
    "            stimulus_sampling_rate=[x[0][0] for x in data[\"samprate\"][0]],\n",
    "            stimulus_resistance=[x[0][0] for x in data[\"RO\"][0]],\n",
    "            stimulus_capacitance=[x[0][0] for x in data[\"CO\"][0]],\n",
    "            stimulus_amplitude_modulation=[x[0][0] for x in data[\"amp_mod\"][0]],\n",
    "            stimulus_waveform_modulation=[x[0][0] for x in data[\"wav_mod\"][0]],\n",
    "            stimulus_value_max=[x[0][0] for x in data[\"maxv\"][0]],\n",
    "            stimulus_value_min=[x[0][0] for x in data[\"minv\"][0]],\n",
    "            waveform=waveforms + [base_waveform],\n",
    "            base_waveform=[base_waveform] * len(data[\"waveform\"][0]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def load_lfp_data(fname, lfp_id_min=301, lfp_id_max=512):\n",
    "    data_means = mat73.loadmat(fname)[\"LfpMeans\"]\n",
    "    experiment_date, session_id, zone, _ = fname.split(\"/\")[-1].split(\"-\")\n",
    "\n",
    "    lfp_means_time = data_means[\"lfptime\"][-1]\n",
    "    lfp_sampling_rate = data_means[\"vdt\"][-1]\n",
    "\n",
    "    # extract the lfp traces\n",
    "    lfp_trace = data_means[\"lfpNorm\"][:-1]\n",
    "    mean_lfp_trace = data_means[\"lfpMean\"][:-1]\n",
    "    base_lfp_trace = data_means[\"b1lfpNorm\"][:-1]\n",
    "    base_mean_lfp_trace = data_means[\"b1lfpMean\"][:-1]\n",
    "\n",
    "    def process_response(list_of_traces):\n",
    "        return [x.T[lfp_id_min:lfp_id_max].min(axis=0) for x in list_of_traces]\n",
    "\n",
    "    # compute the lfp responses for single trials\n",
    "    lfp_response = [process_response(y) for y in lfp_trace]\n",
    "    mean_lfp_response = [process_response(y.reshape(y.shape[0], -1).T) for y in mean_lfp_trace]\n",
    "    base_lfp_response = [process_response(y) for y in base_lfp_trace]\n",
    "    base_mean_lfp_response = [process_response(y.reshape(y.shape[0], -1).T) for y in base_mean_lfp_trace]\n",
    "\n",
    "    def process_response_modulation(list_of_responses, base):\n",
    "        return [list_of_responses[i] / base[i] - 1 for i in range(len(list_of_responses))]\n",
    "\n",
    "    # compute the lfp response modulation for single trials\n",
    "    lfp_response_modulation = [\n",
    "        process_response_modulation(y, base) for y, base in zip(lfp_response, base_mean_lfp_response)\n",
    "    ]\n",
    "\n",
    "    # compute the lfp response modulation for the whole trial\n",
    "    mean_lfp_response_modulation = [\n",
    "        (np.array(mean_lfp_response[i]) / np.array(base_mean_lfp_response[i])).mean() - 1\n",
    "        for i in range(len(mean_lfp_response))\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        dict(\n",
    "            stimulus_marker=[int(x) for x in data_means[\"marker\"][:-1]],\n",
    "            number_bouts=[int(x) for x in data_means[\"bouts\"][:-1]],\n",
    "            lfp_trace=lfp_trace,\n",
    "            mean_lfp_trace=mean_lfp_trace,\n",
    "            base_lfp_trace=base_lfp_trace,\n",
    "            base_mean_lfp_trace=base_mean_lfp_trace,\n",
    "            lfp_response=lfp_response,\n",
    "            mean_lfp_response=mean_lfp_response,\n",
    "            base_lfp_response=base_lfp_response,\n",
    "            base_mean_lfp_response=base_mean_lfp_response,\n",
    "            lfp_response_modulation=lfp_response_modulation,\n",
    "            mean_lfp_response_modulation=mean_lfp_response_modulation,\n",
    "            stimulus_amplitude_modulation=data_means[\"ampmod\"][:-1],\n",
    "            stimulus_waveform_modulation=data_means[\"wavmod\"][:-1],\n",
    "            lfp_sampling_rate=[lfp_sampling_rate] * len(data_means[\"marker\"][:-1]),\n",
    "            lfp_times=[lfp_means_time] * len(data_means[\"marker\"][:-1]),\n",
    "            experiment_date=[experiment_date] * len(data_means[\"marker\"][:-1]),\n",
    "            session_id=[session_id] * len(data_means[\"marker\"][:-1]),\n",
    "            zone=[zone] * len(data_means[\"marker\"][:-1]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def expand_data_to_single_trials(dfrow):\n",
    "    num_bouts = dfrow[\"number_bouts\"]\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(num_bouts):\n",
    "        lfp_trace = list(dfrow[\"lfp_trace\"][i])\n",
    "        mean_lfp_trace = [dfrow[\"mean_lfp_trace\"].reshape(dfrow[\"mean_lfp_trace\"].shape[0], -1).T[i]] * len(lfp_trace)\n",
    "        base_mean_lfp_trace = [\n",
    "            dfrow[\"base_mean_lfp_trace\"].reshape(dfrow[\"base_mean_lfp_trace\"].shape[0], -1).T[i]\n",
    "        ] * len(lfp_trace)\n",
    "        lfp_response = list(dfrow[\"lfp_response\"][i])\n",
    "        mean_lfp_response = [dfrow[\"mean_lfp_response\"][i]] * len(lfp_trace)\n",
    "        base_mean_lfp_response = [dfrow[\"base_mean_lfp_response\"][i]] * len(lfp_trace)\n",
    "        lfp_response_modulation = list(dfrow[\"lfp_response_modulation\"][i])\n",
    "\n",
    "        new_df = pd.concat(\n",
    "            [\n",
    "                new_df,\n",
    "                pd.DataFrame(\n",
    "                    dict(\n",
    "                        lfp_trace=lfp_trace,\n",
    "                        mean_lfp_trace=mean_lfp_trace,\n",
    "                        base_mean_lfp_trace=base_mean_lfp_trace,\n",
    "                        lfp_response=lfp_response,\n",
    "                        mean_lfp_response=mean_lfp_response,\n",
    "                        base_mean_lfp_response=base_mean_lfp_response,\n",
    "                        lfp_response_modulation=lfp_response_modulation,\n",
    "                    ),\n",
    "                ),\n",
    "            ],\n",
    "            axis=0,\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "    for col_name in [\n",
    "        \"stimulus_marker\",\n",
    "        \"number_bouts\",\n",
    "        # \"lfp_trace\",\n",
    "        # \"mean_lfp_trace\",\n",
    "        # DELETED \"base_lfp_trace\",\n",
    "        # \"base_mean_lfp_trace\",\n",
    "        # \"lfp_response\",\n",
    "        # \"mean_lfp_response\",\n",
    "        # DELETED \"base_lfp_response\",\n",
    "        # \"base_mean_lfp_response\",\n",
    "        # \"lfp_response_modulation\",\n",
    "        \"mean_lfp_response_modulation\",\n",
    "        \"stimulus_amplitude_modulation_x\",\n",
    "        \"stimulus_waveform_modulation_x\",\n",
    "        \"lfp_sampling_rate\",\n",
    "        \"lfp_times\",\n",
    "        \"fish_id\",\n",
    "        \"experiment_date\",\n",
    "        \"session_id\",\n",
    "        \"zone\",\n",
    "        \"paired_experiment\",\n",
    "        \"stimulus_fname\",\n",
    "        \"stimulus_sampling_rate\",\n",
    "        \"stimulus_resistance\",\n",
    "        \"stimulus_capacitance\",\n",
    "        \"stimulus_amplitude_modulation_y\",\n",
    "        \"stimulus_waveform_modulation_y\",\n",
    "        \"stimulus_value_max\",\n",
    "        \"stimulus_value_min\",\n",
    "        \"waveform\",\n",
    "        \"base_waveform\",\n",
    "    ]:\n",
    "        new_df[col_name] = [dfrow[col_name]] * new_df.shape[0]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw/fish_03-20190711-separate\n",
      "raw/fish_12-20200826-paired\n",
      "raw/fish_08-20200714-mz\n",
      "raw/fish_02-20190617-dlz\n",
      "raw/fish_06-20200623-separate\n",
      "raw/fish_13-20200902-paired\n",
      "raw/fish_01-20190605-separate\n",
      "raw/fish_10-20200722-separate\n",
      "raw/fish_07-20200626-dlz\n",
      "raw/fish_04-20190731_dlz\n",
      "raw/fish_09-20200715-separate\n",
      "raw/fish_11-20200806-paired\n",
      "raw/fish_05-20190910-mz\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for folder in glob(\"raw/*\", recursive=True):\n",
    "    if os.path.isdir(folder):\n",
    "        print(folder)\n",
    "        fnames = glob(f\"{folder}/*lfp_means.mat\")\n",
    "        waveforms_fname = glob(f\"{folder}/waveform*.mat\")\n",
    "        if len(waveforms_fname) == 1:\n",
    "            fish_id = folder.split(\"/\")[-1].split(\"-\")[0]\n",
    "            waveforms_fname = waveforms_fname[0]\n",
    "            waveforms = load_waveform(waveforms_fname)\n",
    "            new_lfp_data = pd.DataFrame()\n",
    "            for fname in fnames:\n",
    "                lfp_data = load_lfp_data(fname)\n",
    "                new_lfp_data = pd.concat([new_lfp_data, lfp_data], axis=0, ignore_index=True)\n",
    "            new_lfp_data[\"fish_id\"] = fish_id\n",
    "            new_lfp_data[\"paired_experiment\"] = \"paired\" in folder\n",
    "            new_lfp_data = pd.merge(new_lfp_data, waveforms, on=\"stimulus_marker\")\n",
    "        else:\n",
    "            print(f\"Folder {folder} does not contain a waveform file or contains more than one waveform file.\")\n",
    "            continue\n",
    "        data = pd.concat([data, new_lfp_data], axis=0, ignore_index=True)\n",
    "\n",
    "data_single_trials = data.apply(expand_data_to_single_trials, axis=1)  # type: ignore\n",
    "data_single_trials = pd.concat(data_single_trials.tolist(), axis=0, ignore_index=True)\n",
    "data.to_pickle(\"processed/trial_averages.pkl\")\n",
    "data_single_trials.to_pickle(\"processed/single_trials.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
